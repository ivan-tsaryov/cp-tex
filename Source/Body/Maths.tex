\chapter{Расчётная часть}
\section{Безыдентификационная псевдоградиентная адаптация}
Суть псевдоградиентной процедуры применительно к~поставленной задаче в~следующем. На каждой итерации вычисляются оценки параметров привязки в~соответствии с~выражением
\[
\hat{\bar{\alpha}}_{t+1}=\hat{\bar{\alpha}}_{t}-\Lambda_{t}\bar{\beta}_{t}
\]
где: $\bar{\alpha}$ -- \textit{m}-мерный вектор оцениваемых параметров, $t=\overline{0,T}$ -- номер итерации, $\Lambda_{t}$ -- матрица усиления (всегда положительно определенная матрица, как правило диагональная, что исключает собственно матричные вычисления), $\bar{\beta}_{t}$ -- псевдоградиент целевой функции $J(\bar{\alpha})$ (случайный вектор, зависящий в~общем случае от~$\bar{\alpha}_{t-1}$ и~целевой функции $J(\bar{\alpha})$).

Для нестационарных сигналов значения элементов $\lambda_{t}$, $t=\overline{1,T}$, приходится ограничивать снизу для обеспечения вариабельности оценок. Хорошие результаты сходимости оценок можно получить уже при использовании знаковой функции от~значения псевдоградиента на~каждой итерации:
\[
\hat{\bar{\alpha}}_{t+1}=\hat{\bar{\alpha}}_{t}-\Lambda_{t}\text{sign}(\bar{\beta}_{t}),
\]
где
\[
\text{sign}(\beta_{it})= 
\left\{
	\begin{aligned}
		1, &\text{ если } \beta_{it} > 0, \\
		0, &\text{ если } \beta_{it} = 0, \\
		-1, &\text{ если } \beta_{it} < 0, \\
	\end{aligned}
\right.
\]
что значительно упрощает практическую реализацию. 